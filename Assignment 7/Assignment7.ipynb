{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be77bfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "yolo = YOLO('yolov8s.pt')\n",
    "\n",
    "# Load the video capture\n",
    "videoCap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = videoCap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    results = yolo.track(frame, stream=True)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        # get the classes names\n",
    "        classes_names = result.names\n",
    "\n",
    "        # iterate over each box\n",
    "        for box in result.boxes:\n",
    "            # check if confidence is greater than 40 percent\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # get the class\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # get the class name\n",
    "                class_name = classes_names[cls]\n",
    "\n",
    "                # get the respective colour\n",
    "                colour = getColours(cls)\n",
    "\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
    "\n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(frame, f'{classes_names[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                \n",
    "    # show the image\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture and destroy all windows\n",
    "videoCap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0f857a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 288.4ms\n",
      "Speed: 4.7ms preprocess, 288.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 1 clock, 627.4ms\n",
      "Speed: 18.8ms preprocess, 627.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 1 cell phone, 374.2ms\n",
      "Speed: 2.5ms preprocess, 374.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 3 laptops, 451.5ms\n",
      "Speed: 5.7ms preprocess, 451.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 308.7ms\n",
      "Speed: 18.8ms preprocess, 308.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 307.2ms\n",
      "Speed: 4.3ms preprocess, 307.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 443.3ms\n",
      "Speed: 2.3ms preprocess, 443.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 268.0ms\n",
      "Speed: 2.4ms preprocess, 268.0ms inference, 5.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 267.1ms\n",
      "Speed: 2.3ms preprocess, 267.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 264.4ms\n",
      "Speed: 2.9ms preprocess, 264.4ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 726.3ms\n",
      "Speed: 2.0ms preprocess, 726.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 250.7ms\n",
      "Speed: 10.2ms preprocess, 250.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 2 laptops, 452.7ms\n",
      "Speed: 2.3ms preprocess, 452.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 3 laptops, 350.4ms\n",
      "Speed: 3.2ms preprocess, 350.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 4 laptops, 584.6ms\n",
      "Speed: 1.9ms preprocess, 584.6ms inference, 4.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 tv, 4 laptops, 235.6ms\n",
      "Speed: 2.5ms preprocess, 235.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 tv, 1 laptop, 246.7ms\n",
      "Speed: 3.0ms preprocess, 246.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 1 tv, 1 laptop, 286.6ms\n",
      "Speed: 5.4ms preprocess, 286.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 tv, 2 laptops, 249.9ms\n",
      "Speed: 2.8ms preprocess, 249.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 3 laptops, 203.4ms\n",
      "Speed: 2.1ms preprocess, 203.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 tv, 5 laptops, 232.1ms\n",
      "Speed: 2.7ms preprocess, 232.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 2 laptops, 211.4ms\n",
      "Speed: 2.3ms preprocess, 211.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 tv, 3 laptops, 206.0ms\n",
      "Speed: 1.9ms preprocess, 206.0ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 4 laptops, 212.3ms\n",
      "Speed: 2.2ms preprocess, 212.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 4 laptops, 238.9ms\n",
      "Speed: 1.9ms preprocess, 238.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 3 laptops, 242.6ms\n",
      "Speed: 8.6ms preprocess, 242.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 4 laptops, 196.8ms\n",
      "Speed: 1.9ms preprocess, 196.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 243.2ms\n",
      "Speed: 3.7ms preprocess, 243.2ms inference, 3.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 2 laptops, 217.3ms\n",
      "Speed: 2.2ms preprocess, 217.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 194.0ms\n",
      "Speed: 2.2ms preprocess, 194.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 3 laptops, 258.3ms\n",
      "Speed: 2.6ms preprocess, 258.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 3 laptops, 228.6ms\n",
      "Speed: 2.2ms preprocess, 228.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 3 laptops, 218.5ms\n",
      "Speed: 2.5ms preprocess, 218.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 191.6ms\n",
      "Speed: 2.1ms preprocess, 191.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 2 laptops, 250.8ms\n",
      "Speed: 46.2ms preprocess, 250.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 244.1ms\n",
      "Speed: 1.5ms preprocess, 244.1ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 251.5ms\n",
      "Speed: 1.9ms preprocess, 251.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 276.5ms\n",
      "Speed: 2.5ms preprocess, 276.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 256.8ms\n",
      "Speed: 2.3ms preprocess, 256.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 210.0ms\n",
      "Speed: 2.1ms preprocess, 210.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 laptop, 216.5ms\n",
      "Speed: 2.4ms preprocess, 216.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 222.8ms\n",
      "Speed: 2.1ms preprocess, 222.8ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 209.6ms\n",
      "Speed: 2.0ms preprocess, 209.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 216.8ms\n",
      "Speed: 2.0ms preprocess, 216.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 laptop, 244.6ms\n",
      "Speed: 2.1ms preprocess, 244.6ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 229.2ms\n",
      "Speed: 2.1ms preprocess, 229.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 laptop, 215.7ms\n",
      "Speed: 2.3ms preprocess, 215.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 4 laptops, 208.6ms\n",
      "Speed: 2.1ms preprocess, 208.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 335.4ms\n",
      "Speed: 1.9ms preprocess, 335.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 216.8ms\n",
      "Speed: 2.4ms preprocess, 216.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 3 laptops, 232.1ms\n",
      "Speed: 2.0ms preprocess, 232.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 220.0ms\n",
      "Speed: 2.3ms preprocess, 220.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 1 tv, 2 laptops, 216.7ms\n",
      "Speed: 2.2ms preprocess, 216.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 211.8ms\n",
      "Speed: 2.3ms preprocess, 211.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 hot dog, 1 pizza, 3 chairs, 2 laptops, 203.5ms\n",
      "Speed: 2.4ms preprocess, 203.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 chairs, 4 laptops, 216.6ms\n",
      "Speed: 2.1ms preprocess, 216.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 4 laptops, 199.7ms\n",
      "Speed: 1.8ms preprocess, 199.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 3 laptops, 217.3ms\n",
      "Speed: 21.1ms preprocess, 217.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 4 laptops, 267.8ms\n",
      "Speed: 2.2ms preprocess, 267.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 221.3ms\n",
      "Speed: 1.9ms preprocess, 221.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 220.2ms\n",
      "Speed: 1.9ms preprocess, 220.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 222.1ms\n",
      "Speed: 2.8ms preprocess, 222.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 281.0ms\n",
      "Speed: 2.4ms preprocess, 281.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 248.2ms\n",
      "Speed: 2.5ms preprocess, 248.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 2 laptops, 233.2ms\n",
      "Speed: 2.6ms preprocess, 233.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 laptop, 276.2ms\n",
      "Speed: 2.5ms preprocess, 276.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 274.3ms\n",
      "Speed: 2.1ms preprocess, 274.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 246.7ms\n",
      "Speed: 2.1ms preprocess, 246.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 675.3ms\n",
      "Speed: 2.3ms preprocess, 675.3ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 2 laptops, 867.1ms\n",
      "Speed: 5.8ms preprocess, 867.1ms inference, 23.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 1 laptop, 921.7ms\n",
      "Speed: 4.2ms preprocess, 921.7ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 3 chairs, 2 laptops, 379.5ms\n",
      "Speed: 2.9ms preprocess, 379.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 527.2ms\n",
      "Speed: 34.2ms preprocess, 527.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 laptop, 246.6ms\n",
      "Speed: 2.5ms preprocess, 246.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 1 laptop, 259.6ms\n",
      "Speed: 2.5ms preprocess, 259.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 242.5ms\n",
      "Speed: 2.3ms preprocess, 242.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 255.2ms\n",
      "Speed: 3.3ms preprocess, 255.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 2 laptops, 287.0ms\n",
      "Speed: 2.6ms preprocess, 287.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 1 laptop, 246.3ms\n",
      "Speed: 2.3ms preprocess, 246.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 2 laptops, 255.4ms\n",
      "Speed: 2.4ms preprocess, 255.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 1 laptop, 266.2ms\n",
      "Speed: 2.9ms preprocess, 266.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 3 laptops, 295.6ms\n",
      "Speed: 3.1ms preprocess, 295.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 tv, 2 laptops, 261.2ms\n",
      "Speed: 2.6ms preprocess, 261.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 248.7ms\n",
      "Speed: 2.9ms preprocess, 248.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 tv, 3 laptops, 256.6ms\n",
      "Speed: 6.8ms preprocess, 256.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 3 laptops, 281.5ms\n",
      "Speed: 3.4ms preprocess, 281.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 1 tv, 3 laptops, 285.8ms\n",
      "Speed: 2.4ms preprocess, 285.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 1 tv, 3 laptops, 286.3ms\n",
      "Speed: 3.2ms preprocess, 286.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 tv, 3 laptops, 257.4ms\n",
      "Speed: 3.3ms preprocess, 257.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 tvs, 3 laptops, 1 clock, 259.5ms\n",
      "Speed: 3.2ms preprocess, 259.5ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 1 tv, 2 laptops, 1 clock, 277.6ms\n",
      "Speed: 2.4ms preprocess, 277.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 256.2ms\n",
      "Speed: 2.6ms preprocess, 256.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 2 laptops, 1 clock, 231.3ms\n",
      "Speed: 2.3ms preprocess, 231.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 237.1ms\n",
      "Speed: 2.4ms preprocess, 237.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 1 clock, 229.1ms\n",
      "Speed: 2.1ms preprocess, 229.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 3 laptops, 1 clock, 200.5ms\n",
      "Speed: 2.3ms preprocess, 200.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 229.6ms\n",
      "Speed: 2.0ms preprocess, 229.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 222.3ms\n",
      "Speed: 2.4ms preprocess, 222.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 1 tv, 3 laptops, 1 clock, 250.5ms\n",
      "Speed: 2.2ms preprocess, 250.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 1 clock, 245.0ms\n",
      "Speed: 2.4ms preprocess, 245.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 3 laptops, 1 clock, 244.7ms\n",
      "Speed: 2.9ms preprocess, 244.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 tv, 1 laptop, 229.4ms\n",
      "Speed: 2.5ms preprocess, 229.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 2 laptops, 235.7ms\n",
      "Speed: 2.5ms preprocess, 235.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 1 laptop, 244.4ms\n",
      "Speed: 2.5ms preprocess, 244.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 2 laptops, 229.3ms\n",
      "Speed: 2.4ms preprocess, 229.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 2 laptops, 236.4ms\n",
      "Speed: 2.5ms preprocess, 236.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 4 laptops, 1 clock, 314.4ms\n",
      "Speed: 2.4ms preprocess, 314.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 2 laptops, 1 clock, 268.6ms\n",
      "Speed: 2.5ms preprocess, 268.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 3 laptops, 1 clock, 233.3ms\n",
      "Speed: 2.4ms preprocess, 233.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 2 laptops, 248.4ms\n",
      "Speed: 2.7ms preprocess, 248.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 254.1ms\n",
      "Speed: 2.4ms preprocess, 254.1ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 2 chairs, 3 laptops, 242.7ms\n",
      "Speed: 2.5ms preprocess, 242.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 2 laptops, 259.4ms\n",
      "Speed: 2.5ms preprocess, 259.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 2 laptops, 232.7ms\n",
      "Speed: 2.8ms preprocess, 232.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 224.6ms\n",
      "Speed: 2.2ms preprocess, 224.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 3 chairs, 2 laptops, 206.9ms\n",
      "Speed: 1.9ms preprocess, 206.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 2 laptops, 229.3ms\n",
      "Speed: 1.9ms preprocess, 229.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 3 chairs, 2 laptops, 208.7ms\n",
      "Speed: 2.1ms preprocess, 208.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 2 laptops, 209.1ms\n",
      "Speed: 2.1ms preprocess, 209.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 3 laptops, 224.0ms\n",
      "Speed: 2.3ms preprocess, 224.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 3 laptops, 251.4ms\n",
      "Speed: 2.4ms preprocess, 251.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 3 laptops, 220.8ms\n",
      "Speed: 3.6ms preprocess, 220.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 2 laptops, 209.5ms\n",
      "Speed: 1.9ms preprocess, 209.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 217.3ms\n",
      "Speed: 2.3ms preprocess, 217.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 4 chairs, 3 laptops, 200.8ms\n",
      "Speed: 2.1ms preprocess, 200.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 3 laptops, 224.4ms\n",
      "Speed: 1.9ms preprocess, 224.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 2 laptops, 232.1ms\n",
      "Speed: 2.4ms preprocess, 232.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 3 laptops, 246.8ms\n",
      "Speed: 2.5ms preprocess, 246.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 3 laptops, 248.6ms\n",
      "Speed: 2.4ms preprocess, 248.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 4 laptops, 225.3ms\n",
      "Speed: 2.1ms preprocess, 225.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 3 laptops, 281.0ms\n",
      "Speed: 2.7ms preprocess, 281.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 3 laptops, 257.6ms\n",
      "Speed: 2.7ms preprocess, 257.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 chairs, 3 laptops, 248.9ms\n",
      "Speed: 2.5ms preprocess, 248.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 chairs, 2 laptops, 250.3ms\n",
      "Speed: 2.4ms preprocess, 250.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 3 chairs, 3 laptops, 237.0ms\n",
      "Speed: 2.5ms preprocess, 237.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 2 chairs, 3 laptops, 239.1ms\n",
      "Speed: 2.7ms preprocess, 239.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 chairs, 2 laptops, 238.3ms\n",
      "Speed: 5.7ms preprocess, 238.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 3 chairs, 2 laptops, 235.0ms\n",
      "Speed: 2.3ms preprocess, 235.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 persons, 3 chairs, 1 tv, 2 laptops, 237.6ms\n",
      "Speed: 2.3ms preprocess, 237.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 persons, 3 chairs, 1 tv, 3 laptops, 192.5ms\n",
      "Speed: 2.3ms preprocess, 192.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 chairs, 1 tv, 2 laptops, 183.4ms\n",
      "Speed: 2.0ms preprocess, 183.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 chairs, 3 laptops, 224.8ms\n",
      "Speed: 2.3ms preprocess, 224.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 2 laptops, 201.4ms\n",
      "Speed: 2.3ms preprocess, 201.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 3 laptops, 211.1ms\n",
      "Speed: 2.1ms preprocess, 211.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 3 laptops, 208.3ms\n",
      "Speed: 2.7ms preprocess, 208.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 217.2ms\n",
      "Speed: 2.2ms preprocess, 217.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 203.2ms\n",
      "Speed: 1.9ms preprocess, 203.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 191.1ms\n",
      "Speed: 1.9ms preprocess, 191.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 189.1ms\n",
      "Speed: 2.0ms preprocess, 189.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 4 laptops, 211.7ms\n",
      "Speed: 2.6ms preprocess, 211.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 4 laptops, 196.9ms\n",
      "Speed: 1.9ms preprocess, 196.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 4 laptops, 190.7ms\n",
      "Speed: 2.2ms preprocess, 190.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 4 laptops, 187.4ms\n",
      "Speed: 1.9ms preprocess, 187.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 cup, 1 chair, 4 laptops, 212.5ms\n",
      "Speed: 2.2ms preprocess, 212.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 2 chairs, 4 laptops, 191.1ms\n",
      "Speed: 1.9ms preprocess, 191.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 1 laptop, 243.0ms\n",
      "Speed: 2.1ms preprocess, 243.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 189.2ms\n",
      "Speed: 1.9ms preprocess, 189.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 190.7ms\n",
      "Speed: 2.1ms preprocess, 190.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 187.7ms\n",
      "Speed: 2.0ms preprocess, 187.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 laptop, 183.4ms\n",
      "Speed: 1.7ms preprocess, 183.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 191.1ms\n",
      "Speed: 1.9ms preprocess, 191.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 3 laptops, 1 clock, 225.6ms\n",
      "Speed: 1.9ms preprocess, 225.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 3 laptops, 197.6ms\n",
      "Speed: 2.2ms preprocess, 197.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 3 laptops, 1 cell phone, 203.7ms\n",
      "Speed: 2.5ms preprocess, 203.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 2 cell phones, 1 clock, 197.4ms\n",
      "Speed: 2.1ms preprocess, 197.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 4 chairs, 2 laptops, 1 cell phone, 1 clock, 262.7ms\n",
      "Speed: 2.4ms preprocess, 262.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 1 cell phone, 1 clock, 222.4ms\n",
      "Speed: 2.5ms preprocess, 222.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 224.1ms\n",
      "Speed: 2.3ms preprocess, 224.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 1 cell phone, 221.6ms\n",
      "Speed: 2.1ms preprocess, 221.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 2 laptops, 1 cell phone, 222.8ms\n",
      "Speed: 2.6ms preprocess, 222.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 1 tv, 2 laptops, 1 cell phone, 1 clock, 230.9ms\n",
      "Speed: 2.9ms preprocess, 230.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 224.0ms\n",
      "Speed: 2.1ms preprocess, 224.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 1 tv, 3 laptops, 1 clock, 252.6ms\n",
      "Speed: 2.6ms preprocess, 252.6ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 1 hot dog, 4 chairs, 2 laptops, 1 clock, 239.9ms\n",
      "Speed: 3.9ms preprocess, 239.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 243.4ms\n",
      "Speed: 2.7ms preprocess, 243.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 239.7ms\n",
      "Speed: 2.4ms preprocess, 239.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 1 clock, 258.2ms\n",
      "Speed: 2.6ms preprocess, 258.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 tv, 2 laptops, 234.8ms\n",
      "Speed: 2.9ms preprocess, 234.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 270.2ms\n",
      "Speed: 2.4ms preprocess, 270.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 274.2ms\n",
      "Speed: 3.2ms preprocess, 274.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 230.1ms\n",
      "Speed: 2.3ms preprocess, 230.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 2 laptops, 1 clock, 218.6ms\n",
      "Speed: 2.6ms preprocess, 218.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 241.6ms\n",
      "Speed: 2.4ms preprocess, 241.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 1 clock, 222.7ms\n",
      "Speed: 2.1ms preprocess, 222.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 237.5ms\n",
      "Speed: 2.3ms preprocess, 237.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 250.5ms\n",
      "Speed: 2.1ms preprocess, 250.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 1 clock, 249.3ms\n",
      "Speed: 2.4ms preprocess, 249.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 tv, 3 laptops, 1 clock, 236.0ms\n",
      "Speed: 2.7ms preprocess, 236.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 1 clock, 243.4ms\n",
      "Speed: 2.7ms preprocess, 243.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 245.4ms\n",
      "Speed: 2.4ms preprocess, 245.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 243.3ms\n",
      "Speed: 2.4ms preprocess, 243.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 1 clock, 244.2ms\n",
      "Speed: 3.5ms preprocess, 244.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 1 clock, 241.3ms\n",
      "Speed: 2.7ms preprocess, 241.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 1 laptop, 1 clock, 242.6ms\n",
      "Speed: 2.3ms preprocess, 242.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 1 clock, 239.9ms\n",
      "Speed: 2.2ms preprocess, 239.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 236.9ms\n",
      "Speed: 2.3ms preprocess, 236.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 1 laptop, 1 clock, 246.1ms\n",
      "Speed: 5.2ms preprocess, 246.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 1 clock, 248.8ms\n",
      "Speed: 2.9ms preprocess, 248.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 1 laptop, 246.9ms\n",
      "Speed: 2.6ms preprocess, 246.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 1 laptop, 234.2ms\n",
      "Speed: 2.3ms preprocess, 234.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 1 laptop, 1 clock, 227.1ms\n",
      "Speed: 2.3ms preprocess, 227.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 1 clock, 213.7ms\n",
      "Speed: 2.5ms preprocess, 213.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 1 laptop, 1 clock, 229.6ms\n",
      "Speed: 2.0ms preprocess, 229.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 1 laptop, 1 clock, 254.2ms\n",
      "Speed: 2.5ms preprocess, 254.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 237.6ms\n",
      "Speed: 2.6ms preprocess, 237.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 laptop, 1 remote, 228.2ms\n",
      "Speed: 2.1ms preprocess, 228.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 laptop, 1 scissors, 232.6ms\n",
      "Speed: 2.7ms preprocess, 232.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 laptop, 227.9ms\n",
      "Speed: 2.5ms preprocess, 227.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 laptop, 230.4ms\n",
      "Speed: 2.7ms preprocess, 230.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 laptop, 226.2ms\n",
      "Speed: 2.8ms preprocess, 226.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 221.8ms\n",
      "Speed: 2.4ms preprocess, 221.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 246.9ms\n",
      "Speed: 2.6ms preprocess, 246.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 laptop, 233.3ms\n",
      "Speed: 2.0ms preprocess, 233.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 251.1ms\n",
      "Speed: 2.4ms preprocess, 251.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 laptop, 265.3ms\n",
      "Speed: 3.8ms preprocess, 265.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 clock, 236.0ms\n",
      "Speed: 2.5ms preprocess, 236.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 261.2ms\n",
      "Speed: 2.7ms preprocess, 261.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 laptop, 1 clock, 216.7ms\n",
      "Speed: 2.5ms preprocess, 216.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 224.1ms\n",
      "Speed: 2.1ms preprocess, 224.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 2 chairs, 2 laptops, 217.6ms\n",
      "Speed: 1.9ms preprocess, 217.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 3 chairs, 2 laptops, 206.2ms\n",
      "Speed: 2.4ms preprocess, 206.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 2 donuts, 4 chairs, 3 laptops, 211.7ms\n",
      "Speed: 2.4ms preprocess, 211.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 donuts, 5 chairs, 1 laptop, 226.6ms\n",
      "Speed: 2.3ms preprocess, 226.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 223.9ms\n",
      "Speed: 2.1ms preprocess, 223.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 204.9ms\n",
      "Speed: 2.0ms preprocess, 204.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 1 clock, 233.3ms\n",
      "Speed: 2.2ms preprocess, 233.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 253.7ms\n",
      "Speed: 2.5ms preprocess, 253.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 254.2ms\n",
      "Speed: 2.2ms preprocess, 254.2ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 245.1ms\n",
      "Speed: 2.3ms preprocess, 245.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 231.4ms\n",
      "Speed: 2.2ms preprocess, 231.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 257.9ms\n",
      "Speed: 2.3ms preprocess, 257.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 257.2ms\n",
      "Speed: 2.3ms preprocess, 257.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 276.9ms\n",
      "Speed: 2.6ms preprocess, 276.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 258.6ms\n",
      "Speed: 2.3ms preprocess, 258.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 1 laptop, 1 remote, 259.4ms\n",
      "Speed: 2.4ms preprocess, 259.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 247.8ms\n",
      "Speed: 2.6ms preprocess, 247.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 chair, 1 remote, 262.2ms\n",
      "Speed: 2.4ms preprocess, 262.2ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 remote, 275.5ms\n",
      "Speed: 2.9ms preprocess, 275.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 250.3ms\n",
      "Speed: 2.5ms preprocess, 250.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 244.4ms\n",
      "Speed: 2.9ms preprocess, 244.4ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 1 scissors, 251.2ms\n",
      "Speed: 2.4ms preprocess, 251.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 242.5ms\n",
      "Speed: 2.4ms preprocess, 242.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 1 chair, 205.0ms\n",
      "Speed: 2.4ms preprocess, 205.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 246.3ms\n",
      "Speed: 2.2ms preprocess, 246.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 chairs, 3 laptops, 1 toothbrush, 216.6ms\n",
      "Speed: 2.4ms preprocess, 216.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 2 chairs, 2 laptops, 1 toothbrush, 212.5ms\n",
      "Speed: 2.2ms preprocess, 212.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 3 chairs, 2 laptops, 237.5ms\n",
      "Speed: 1.9ms preprocess, 237.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 239.4ms\n",
      "Speed: 2.7ms preprocess, 239.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 222.8ms\n",
      "Speed: 2.2ms preprocess, 222.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 1 tv, 2 laptops, 208.5ms\n",
      "Speed: 2.5ms preprocess, 208.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 244.0ms\n",
      "Speed: 2.2ms preprocess, 244.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 tv, 2 laptops, 1 clock, 194.4ms\n",
      "Speed: 2.1ms preprocess, 194.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 1 laptop, 1 clock, 194.3ms\n",
      "Speed: 2.0ms preprocess, 194.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 laptop, 1 clock, 193.0ms\n",
      "Speed: 2.4ms preprocess, 193.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 laptop, 1 clock, 196.7ms\n",
      "Speed: 2.5ms preprocess, 196.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 1 laptop, 1 clock, 199.2ms\n",
      "Speed: 2.2ms preprocess, 199.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 laptop, 209.2ms\n",
      "Speed: 2.0ms preprocess, 209.2ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 206.0ms\n",
      "Speed: 1.9ms preprocess, 206.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 laptop, 1 clock, 219.7ms\n",
      "Speed: 2.0ms preprocess, 219.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 1 laptop, 242.8ms\n",
      "Speed: 2.4ms preprocess, 242.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 1 laptop, 216.6ms\n",
      "Speed: 2.1ms preprocess, 216.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 1 laptop, 191.8ms\n",
      "Speed: 2.0ms preprocess, 191.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 1 clock, 193.0ms\n",
      "Speed: 2.2ms preprocess, 193.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 200.0ms\n",
      "Speed: 1.9ms preprocess, 200.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 191.0ms\n",
      "Speed: 2.4ms preprocess, 191.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 1 clock, 196.5ms\n",
      "Speed: 2.0ms preprocess, 196.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 2 laptops, 1 clock, 210.8ms\n",
      "Speed: 2.1ms preprocess, 210.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 3 laptops, 1 clock, 207.6ms\n",
      "Speed: 4.7ms preprocess, 207.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 2 scissorss, 195.8ms\n",
      "Speed: 2.0ms preprocess, 195.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 chairs, 3 laptops, 213.6ms\n",
      "Speed: 1.9ms preprocess, 213.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 2 laptops, 254.3ms\n",
      "Speed: 2.3ms preprocess, 254.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 2 laptops, 247.8ms\n",
      "Speed: 2.4ms preprocess, 247.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 2 laptops, 225.4ms\n",
      "Speed: 2.3ms preprocess, 225.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 5 chairs, 2 laptops, 1 cell phone, 244.3ms\n",
      "Speed: 2.3ms preprocess, 244.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 1 clock, 247.1ms\n",
      "Speed: 2.7ms preprocess, 247.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 5 chairs, 2 laptops, 245.6ms\n",
      "Speed: 2.8ms preprocess, 245.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 1 clock, 243.5ms\n",
      "Speed: 2.4ms preprocess, 243.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 258.3ms\n",
      "Speed: 2.2ms preprocess, 258.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 235.5ms\n",
      "Speed: 2.4ms preprocess, 235.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 276.9ms\n",
      "Speed: 2.4ms preprocess, 276.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 1 clock, 242.0ms\n",
      "Speed: 2.6ms preprocess, 242.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 1 clock, 286.0ms\n",
      "Speed: 2.4ms preprocess, 286.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 257.1ms\n",
      "Speed: 2.9ms preprocess, 257.1ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 1 laptop, 1 clock, 249.1ms\n",
      "Speed: 2.4ms preprocess, 249.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 244.4ms\n",
      "Speed: 2.4ms preprocess, 244.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 4 chairs, 2 laptops, 266.0ms\n",
      "Speed: 2.4ms preprocess, 266.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 278.5ms\n",
      "Speed: 2.4ms preprocess, 278.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 2 laptops, 268.2ms\n",
      "Speed: 2.4ms preprocess, 268.2ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 272.9ms\n",
      "Speed: 2.7ms preprocess, 272.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 288.3ms\n",
      "Speed: 2.6ms preprocess, 288.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 303.9ms\n",
      "Speed: 2.4ms preprocess, 303.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 262.2ms\n",
      "Speed: 2.3ms preprocess, 262.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 253.7ms\n",
      "Speed: 3.3ms preprocess, 253.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 281.0ms\n",
      "Speed: 2.8ms preprocess, 281.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 259.6ms\n",
      "Speed: 4.6ms preprocess, 259.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 243.6ms\n",
      "Speed: 2.3ms preprocess, 243.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 288.7ms\n",
      "Speed: 3.1ms preprocess, 288.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 267.6ms\n",
      "Speed: 2.6ms preprocess, 267.6ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 294.9ms\n",
      "Speed: 2.9ms preprocess, 294.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 252.5ms\n",
      "Speed: 2.9ms preprocess, 252.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 269.0ms\n",
      "Speed: 2.2ms preprocess, 269.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 248.0ms\n",
      "Speed: 2.4ms preprocess, 248.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 247.2ms\n",
      "Speed: 2.6ms preprocess, 247.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 229.2ms\n",
      "Speed: 2.3ms preprocess, 229.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 244.4ms\n",
      "Speed: 2.3ms preprocess, 244.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 255.4ms\n",
      "Speed: 2.7ms preprocess, 255.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 237.7ms\n",
      "Speed: 2.5ms preprocess, 237.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 253.4ms\n",
      "Speed: 2.4ms preprocess, 253.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 cat, 4 chairs, 2 laptops, 257.7ms\n",
      "Speed: 2.1ms preprocess, 257.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 258.9ms\n",
      "Speed: 2.4ms preprocess, 258.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 285.3ms\n",
      "Speed: 2.4ms preprocess, 285.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 chairs, 280.0ms\n",
      "Speed: 3.1ms preprocess, 280.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 chair, 3 laptops, 244.5ms\n",
      "Speed: 2.4ms preprocess, 244.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 2 laptops, 234.5ms\n",
      "Speed: 2.2ms preprocess, 234.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 2 laptops, 244.4ms\n",
      "Speed: 2.4ms preprocess, 244.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 3 laptops, 251.2ms\n",
      "Speed: 2.4ms preprocess, 251.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 256.0ms\n",
      "Speed: 2.4ms preprocess, 256.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 1 toothbrush, 256.3ms\n",
      "Speed: 2.4ms preprocess, 256.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 3 laptops, 250.1ms\n",
      "Speed: 3.8ms preprocess, 250.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 3 laptops, 277.7ms\n",
      "Speed: 2.4ms preprocess, 277.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 chairs, 3 laptops, 222.0ms\n",
      "Speed: 2.7ms preprocess, 222.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 3 laptops, 225.5ms\n",
      "Speed: 2.4ms preprocess, 225.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 3 laptops, 232.5ms\n",
      "Speed: 2.4ms preprocess, 232.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 2 chairs, 2 laptops, 232.6ms\n",
      "Speed: 2.1ms preprocess, 232.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 1 clock, 236.5ms\n",
      "Speed: 1.8ms preprocess, 236.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 4 laptops, 1 clock, 233.0ms\n",
      "Speed: 2.4ms preprocess, 233.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 4 laptops, 1 clock, 210.6ms\n",
      "Speed: 2.0ms preprocess, 210.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 4 chairs, 3 laptops, 1 clock, 208.3ms\n",
      "Speed: 2.5ms preprocess, 208.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 4 chairs, 3 laptops, 1 clock, 228.0ms\n",
      "Speed: 2.3ms preprocess, 228.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 224.0ms\n",
      "Speed: 2.4ms preprocess, 224.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 4 chairs, 4 laptops, 1 clock, 235.0ms\n",
      "Speed: 2.4ms preprocess, 235.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 4 chairs, 2 laptops, 1 clock, 231.8ms\n",
      "Speed: 3.3ms preprocess, 231.8ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 1 clock, 224.6ms\n",
      "Speed: 2.7ms preprocess, 224.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 218.5ms\n",
      "Speed: 2.6ms preprocess, 218.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 229.7ms\n",
      "Speed: 2.4ms preprocess, 229.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 215.9ms\n",
      "Speed: 2.2ms preprocess, 215.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 221.2ms\n",
      "Speed: 2.2ms preprocess, 221.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 206.8ms\n",
      "Speed: 2.3ms preprocess, 206.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 225.7ms\n",
      "Speed: 2.5ms preprocess, 225.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 237.1ms\n",
      "Speed: 2.2ms preprocess, 237.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 248.6ms\n",
      "Speed: 2.3ms preprocess, 248.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 212.7ms\n",
      "Speed: 2.2ms preprocess, 212.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 1 clock, 226.4ms\n",
      "Speed: 2.6ms preprocess, 226.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 1 clock, 220.8ms\n",
      "Speed: 2.4ms preprocess, 220.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 chairs, 221.8ms\n",
      "Speed: 2.4ms preprocess, 221.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 227.8ms\n",
      "Speed: 2.5ms preprocess, 227.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 3 laptops, 247.6ms\n",
      "Speed: 2.5ms preprocess, 247.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 bottle, 2 chairs, 3 laptops, 219.9ms\n",
      "Speed: 2.5ms preprocess, 219.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 1 donut, 3 chairs, 2 laptops, 215.4ms\n",
      "Speed: 2.2ms preprocess, 215.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 3 chairs, 3 laptops, 192.3ms\n",
      "Speed: 2.4ms preprocess, 192.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 3 chairs, 2 laptops, 244.6ms\n",
      "Speed: 2.5ms preprocess, 244.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 3 chairs, 3 laptops, 1 remote, 244.0ms\n",
      "Speed: 2.4ms preprocess, 244.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 3 chairs, 3 laptops, 219.2ms\n",
      "Speed: 2.4ms preprocess, 219.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 3 chairs, 3 laptops, 239.3ms\n",
      "Speed: 2.4ms preprocess, 239.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 2 chairs, 3 laptops, 249.1ms\n",
      "Speed: 2.4ms preprocess, 249.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 cat, 1 donut, 2 chairs, 2 laptops, 242.4ms\n",
      "Speed: 2.4ms preprocess, 242.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 3 chairs, 3 laptops, 262.9ms\n",
      "Speed: 2.4ms preprocess, 262.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 donuts, 3 chairs, 2 laptops, 244.3ms\n",
      "Speed: 2.9ms preprocess, 244.3ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 252.2ms\n",
      "Speed: 2.4ms preprocess, 252.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 3 laptops, 249.5ms\n",
      "Speed: 2.6ms preprocess, 249.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 3 laptops, 258.6ms\n",
      "Speed: 2.8ms preprocess, 258.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 3 laptops, 277.5ms\n",
      "Speed: 2.5ms preprocess, 277.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 3 laptops, 241.0ms\n",
      "Speed: 2.4ms preprocess, 241.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 2 chairs, 2 laptops, 257.2ms\n",
      "Speed: 2.8ms preprocess, 257.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 2 chairs, 2 laptops, 268.7ms\n",
      "Speed: 3.6ms preprocess, 268.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 3 laptops, 247.9ms\n",
      "Speed: 2.4ms preprocess, 247.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 2 laptops, 244.2ms\n",
      "Speed: 2.6ms preprocess, 244.2ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 3 chairs, 2 laptops, 246.1ms\n",
      "Speed: 2.3ms preprocess, 246.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 2 laptops, 240.8ms\n",
      "Speed: 2.5ms preprocess, 240.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 3 chairs, 3 laptops, 244.4ms\n",
      "Speed: 2.5ms preprocess, 244.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 2 chairs, 3 laptops, 240.4ms\n",
      "Speed: 3.5ms preprocess, 240.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 2 laptops, 1 remote, 248.9ms\n",
      "Speed: 3.1ms preprocess, 248.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 2 chairs, 3 laptops, 260.7ms\n",
      "Speed: 2.6ms preprocess, 260.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 3 laptops, 262.5ms\n",
      "Speed: 2.2ms preprocess, 262.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 2 laptops, 239.9ms\n",
      "Speed: 2.7ms preprocess, 239.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 2 chairs, 2 laptops, 255.7ms\n",
      "Speed: 2.5ms preprocess, 255.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 3 chairs, 3 laptops, 266.7ms\n",
      "Speed: 2.8ms preprocess, 266.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 2 chairs, 3 laptops, 249.5ms\n",
      "Speed: 2.4ms preprocess, 249.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 2 chairs, 3 laptops, 234.8ms\n",
      "Speed: 3.2ms preprocess, 234.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 2 chairs, 2 laptops, 1 remote, 285.9ms\n",
      "Speed: 2.2ms preprocess, 285.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 1 donut, 2 chairs, 3 laptops, 266.9ms\n",
      "Speed: 2.2ms preprocess, 266.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 3 chairs, 2 laptops, 1 clock, 328.7ms\n",
      "Speed: 2.4ms preprocess, 328.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 donut, 1 chair, 2 laptops, 1 clock, 305.0ms\n",
      "Speed: 2.3ms preprocess, 305.0ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 271.3ms\n",
      "Speed: 2.5ms preprocess, 271.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 1 tie, 2 chairs, 2 laptops, 1 clock, 270.2ms\n",
      "Speed: 2.6ms preprocess, 270.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 2 chairs, 3 laptops, 260.5ms\n",
      "Speed: 2.5ms preprocess, 260.5ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 1 donut, 3 chairs, 2 laptops, 276.1ms\n",
      "Speed: 2.2ms preprocess, 276.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 316.7ms\n",
      "Speed: 2.4ms preprocess, 316.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 2 chairs, 2 laptops, 277.6ms\n",
      "Speed: 2.4ms preprocess, 277.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 chairs, 3 laptops, 248.2ms\n",
      "Speed: 2.4ms preprocess, 248.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 2 laptops, 276.9ms\n",
      "Speed: 2.7ms preprocess, 276.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 2 chairs, 2 laptops, 283.7ms\n",
      "Speed: 2.5ms preprocess, 283.7ms inference, 4.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 2 chairs, 2 laptops, 289.3ms\n",
      "Speed: 2.5ms preprocess, 289.3ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 1 chair, 245.4ms\n",
      "Speed: 3.4ms preprocess, 245.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 2 chairs, 244.9ms\n",
      "Speed: 2.4ms preprocess, 244.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 persons, 1 cup, 1 chair, 256.2ms\n",
      "Speed: 2.4ms preprocess, 256.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 3 chairs, 263.8ms\n",
      "Speed: 2.6ms preprocess, 263.8ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 6 persons, 3 chairs, 3 laptops, 245.9ms\n",
      "Speed: 2.4ms preprocess, 245.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 2 chairs, 2 laptops, 1 remote, 251.8ms\n",
      "Speed: 2.5ms preprocess, 251.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 1 tie, 3 chairs, 2 laptops, 254.7ms\n",
      "Speed: 2.4ms preprocess, 254.7ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 3 chairs, 3 laptops, 267.9ms\n",
      "Speed: 2.4ms preprocess, 267.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 2 laptops, 282.4ms\n",
      "Speed: 2.6ms preprocess, 282.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 4 chairs, 1 laptop, 270.3ms\n",
      "Speed: 2.4ms preprocess, 270.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 3 chairs, 1 laptop, 238.3ms\n",
      "Speed: 2.4ms preprocess, 238.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 3 chairs, 2 laptops, 271.2ms\n",
      "Speed: 2.4ms preprocess, 271.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 241.6ms\n",
      "Speed: 2.5ms preprocess, 241.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 247.5ms\n",
      "Speed: 2.5ms preprocess, 247.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 252.4ms\n",
      "Speed: 2.6ms preprocess, 252.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 2 laptops, 243.0ms\n",
      "Speed: 2.4ms preprocess, 243.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 284.2ms\n",
      "Speed: 2.6ms preprocess, 284.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 3 chairs, 2 laptops, 255.9ms\n",
      "Speed: 2.5ms preprocess, 255.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 persons, 1 donut, 2 chairs, 252.4ms\n",
      "Speed: 2.6ms preprocess, 252.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 1 dining table, 252.1ms\n",
      "Speed: 2.4ms preprocess, 252.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 247.6ms\n",
      "Speed: 2.5ms preprocess, 247.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 4 laptops, 1 clock, 247.9ms\n",
      "Speed: 2.5ms preprocess, 247.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 3 laptops, 1 clock, 232.5ms\n",
      "Speed: 2.4ms preprocess, 232.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 256.7ms\n",
      "Speed: 2.3ms preprocess, 256.7ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 4 chairs, 3 laptops, 1 clock, 258.3ms\n",
      "Speed: 2.3ms preprocess, 258.3ms inference, 5.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 251.5ms\n",
      "Speed: 2.5ms preprocess, 251.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 246.8ms\n",
      "Speed: 2.5ms preprocess, 246.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 256.0ms\n",
      "Speed: 2.3ms preprocess, 256.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 249.1ms\n",
      "Speed: 2.3ms preprocess, 249.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 1 clock, 237.5ms\n",
      "Speed: 2.5ms preprocess, 237.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 242.3ms\n",
      "Speed: 2.3ms preprocess, 242.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 3 laptops, 1 clock, 256.9ms\n",
      "Speed: 2.5ms preprocess, 256.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 239.3ms\n",
      "Speed: 2.4ms preprocess, 239.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 242.0ms\n",
      "Speed: 2.5ms preprocess, 242.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 243.9ms\n",
      "Speed: 2.5ms preprocess, 243.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 4 laptops, 244.3ms\n",
      "Speed: 2.6ms preprocess, 244.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 225.4ms\n",
      "Speed: 2.5ms preprocess, 225.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 3 laptops, 260.2ms\n",
      "Speed: 2.3ms preprocess, 260.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 216.5ms\n",
      "Speed: 2.5ms preprocess, 216.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 199.0ms\n",
      "Speed: 1.9ms preprocess, 199.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 7 persons, 5 chairs, 2 laptops, 189.6ms\n",
      "Speed: 2.1ms preprocess, 189.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 220.5ms\n",
      "Speed: 1.9ms preprocess, 220.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 196.7ms\n",
      "Speed: 2.1ms preprocess, 196.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 193.9ms\n",
      "Speed: 2.2ms preprocess, 193.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 4 laptops, 1 clock, 191.3ms\n",
      "Speed: 2.1ms preprocess, 191.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 214.1ms\n",
      "Speed: 2.5ms preprocess, 214.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 208.1ms\n",
      "Speed: 2.2ms preprocess, 208.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 191.0ms\n",
      "Speed: 2.0ms preprocess, 191.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 212.6ms\n",
      "Speed: 2.2ms preprocess, 212.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 215.4ms\n",
      "Speed: 2.0ms preprocess, 215.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 2 laptops, 194.3ms\n",
      "Speed: 2.0ms preprocess, 194.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 191.2ms\n",
      "Speed: 2.4ms preprocess, 191.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 2 laptops, 1 clock, 188.2ms\n",
      "Speed: 2.1ms preprocess, 188.2ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 2 laptops, 205.9ms\n",
      "Speed: 2.0ms preprocess, 205.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 199.6ms\n",
      "Speed: 2.2ms preprocess, 199.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 195.1ms\n",
      "Speed: 2.2ms preprocess, 195.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 193.6ms\n",
      "Speed: 2.1ms preprocess, 193.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 1 laptop, 228.1ms\n",
      "Speed: 1.9ms preprocess, 228.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 203.7ms\n",
      "Speed: 2.4ms preprocess, 203.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 3 laptops, 1 clock, 205.9ms\n",
      "Speed: 2.2ms preprocess, 205.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 198.3ms\n",
      "Speed: 2.1ms preprocess, 198.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 209.1ms\n",
      "Speed: 3.4ms preprocess, 209.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 1 clock, 197.3ms\n",
      "Speed: 1.9ms preprocess, 197.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 1 clock, 190.7ms\n",
      "Speed: 2.3ms preprocess, 190.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 2 laptops, 1 clock, 193.8ms\n",
      "Speed: 2.3ms preprocess, 193.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 211.7ms\n",
      "Speed: 2.4ms preprocess, 211.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 198.3ms\n",
      "Speed: 1.9ms preprocess, 198.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 2 laptops, 1 clock, 194.1ms\n",
      "Speed: 1.9ms preprocess, 194.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 4 laptops, 1 clock, 189.4ms\n",
      "Speed: 2.2ms preprocess, 189.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 4 chairs, 3 laptops, 1 clock, 222.8ms\n",
      "Speed: 2.2ms preprocess, 222.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 208.1ms\n",
      "Speed: 2.1ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 191.5ms\n",
      "Speed: 2.0ms preprocess, 191.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 5 chairs, 3 laptops, 203.9ms\n",
      "Speed: 2.2ms preprocess, 203.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 211.8ms\n",
      "Speed: 2.3ms preprocess, 211.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 203.0ms\n",
      "Speed: 2.2ms preprocess, 203.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 201.0ms\n",
      "Speed: 2.4ms preprocess, 201.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 209.0ms\n",
      "Speed: 2.1ms preprocess, 209.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 4 chairs, 3 laptops, 1 clock, 215.2ms\n",
      "Speed: 2.3ms preprocess, 215.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 220.1ms\n",
      "Speed: 2.3ms preprocess, 220.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 4 laptops, 223.4ms\n",
      "Speed: 2.4ms preprocess, 223.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 4 chairs, 3 laptops, 270.6ms\n",
      "Speed: 2.4ms preprocess, 270.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 4 chairs, 3 laptops, 247.7ms\n",
      "Speed: 2.3ms preprocess, 247.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 3 laptops, 1 clock, 232.0ms\n",
      "Speed: 2.3ms preprocess, 232.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 2 laptops, 1 clock, 234.3ms\n",
      "Speed: 3.3ms preprocess, 234.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 3 laptops, 1 clock, 250.5ms\n",
      "Speed: 2.5ms preprocess, 250.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 9 persons, 6 chairs, 3 laptops, 1 clock, 241.3ms\n",
      "Speed: 2.4ms preprocess, 241.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 3 laptops, 1 clock, 241.6ms\n",
      "Speed: 2.5ms preprocess, 241.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 240.8ms\n",
      "Speed: 2.3ms preprocess, 240.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 235.6ms\n",
      "Speed: 2.4ms preprocess, 235.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 2 laptops, 1 clock, 223.7ms\n",
      "Speed: 2.4ms preprocess, 223.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 4 laptops, 1 clock, 255.0ms\n",
      "Speed: 2.7ms preprocess, 255.0ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 6 chairs, 3 laptops, 250.2ms\n",
      "Speed: 2.9ms preprocess, 250.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 2 laptops, 1 clock, 261.9ms\n",
      "Speed: 2.6ms preprocess, 261.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 6 chairs, 3 laptops, 1 clock, 235.9ms\n",
      "Speed: 2.2ms preprocess, 235.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 1 clock, 255.2ms\n",
      "Speed: 2.5ms preprocess, 255.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 3 laptops, 1 clock, 235.2ms\n",
      "Speed: 2.5ms preprocess, 235.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 persons, 5 chairs, 2 laptops, 252.2ms\n",
      "Speed: 2.5ms preprocess, 252.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 2 laptops, 239.7ms\n",
      "Speed: 2.0ms preprocess, 239.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 250.9ms\n",
      "Speed: 2.4ms preprocess, 250.9ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 238.8ms\n",
      "Speed: 2.4ms preprocess, 238.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 250.0ms\n",
      "Speed: 2.7ms preprocess, 250.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 10 persons, 5 chairs, 2 laptops, 1 clock, 263.3ms\n",
      "Speed: 2.4ms preprocess, 263.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 2 laptops, 227.6ms\n",
      "Speed: 2.6ms preprocess, 227.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 1 laptop, 1 clock, 250.7ms\n",
      "Speed: 2.5ms preprocess, 250.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 6 chairs, 2 laptops, 1 clock, 238.8ms\n",
      "Speed: 2.4ms preprocess, 238.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 2 laptops, 1 clock, 258.0ms\n",
      "Speed: 3.8ms preprocess, 258.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 2 laptops, 1 clock, 228.5ms\n",
      "Speed: 2.2ms preprocess, 228.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 1 clock, 246.0ms\n",
      "Speed: 2.6ms preprocess, 246.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 2 laptops, 243.9ms\n",
      "Speed: 2.6ms preprocess, 243.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 2 laptops, 241.3ms\n",
      "Speed: 2.6ms preprocess, 241.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 261.9ms\n",
      "Speed: 2.2ms preprocess, 261.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 1 clock, 245.4ms\n",
      "Speed: 2.4ms preprocess, 245.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 246.8ms\n",
      "Speed: 2.4ms preprocess, 246.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 250.4ms\n",
      "Speed: 2.6ms preprocess, 250.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 256.1ms\n",
      "Speed: 2.5ms preprocess, 256.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 1 clock, 239.0ms\n",
      "Speed: 2.6ms preprocess, 239.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 257.8ms\n",
      "Speed: 2.4ms preprocess, 257.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 1 clock, 394.1ms\n",
      "Speed: 12.6ms preprocess, 394.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 251.2ms\n",
      "Speed: 3.3ms preprocess, 251.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 6 chairs, 2 laptops, 1 clock, 274.6ms\n",
      "Speed: 2.8ms preprocess, 274.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 3 laptops, 1 clock, 254.0ms\n",
      "Speed: 2.6ms preprocess, 254.0ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 1 clock, 272.2ms\n",
      "Speed: 2.7ms preprocess, 272.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 11 persons, 5 chairs, 2 laptops, 1 clock, 608.3ms\n",
      "Speed: 2.5ms preprocess, 608.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 2 laptops, 1 clock, 655.1ms\n",
      "Speed: 6.1ms preprocess, 655.1ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 1 clock, 477.8ms\n",
      "Speed: 2.5ms preprocess, 477.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 3 laptops, 711.8ms\n",
      "Speed: 2.3ms preprocess, 711.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 1 clock, 556.7ms\n",
      "Speed: 13.1ms preprocess, 556.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 1 laptop, 1 clock, 317.8ms\n",
      "Speed: 6.9ms preprocess, 317.8ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 282.6ms\n",
      "Speed: 2.0ms preprocess, 282.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 3 laptops, 1 clock, 235.1ms\n",
      "Speed: 3.4ms preprocess, 235.1ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 333.5ms\n",
      "Speed: 2.6ms preprocess, 333.5ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 1 clock, 256.7ms\n",
      "Speed: 3.6ms preprocess, 256.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 4 laptops, 1 clock, 249.2ms\n",
      "Speed: 2.4ms preprocess, 249.2ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 202.4ms\n",
      "Speed: 2.2ms preprocess, 202.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 2 laptops, 1 clock, 197.5ms\n",
      "Speed: 2.1ms preprocess, 197.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 2 laptops, 1 clock, 218.6ms\n",
      "Speed: 1.9ms preprocess, 218.6ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 254.1ms\n",
      "Speed: 4.1ms preprocess, 254.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 6 chairs, 1 laptop, 234.7ms\n",
      "Speed: 2.1ms preprocess, 234.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 persons, 5 chairs, 2 laptops, 1 clock, 230.4ms\n",
      "Speed: 5.8ms preprocess, 230.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 13 persons, 5 chairs, 3 laptops, 1 clock, 207.5ms\n",
      "Speed: 2.3ms preprocess, 207.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 14 persons, 5 chairs, 2 laptops, 1 clock, 199.8ms\n",
      "Speed: 2.7ms preprocess, 199.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 15 persons, 5 chairs, 2 laptops, 1 clock, 192.6ms\n",
      "Speed: 2.1ms preprocess, 192.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     24\u001b[0m results \u001b[38;5;241m=\u001b[39m yolo\u001b[38;5;241m.\u001b[39mtrack(frame, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# get the classes names\u001b[39;49;00m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses_names\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# iterate over each box\u001b[39;49;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:330\u001b[0m, in \u001b[0;36mBasePredictor.stream_inference\u001b[1;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;66;03m# Inference\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m profilers[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m--> 330\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    331\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m [preds] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(preds, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m preds  \u001b[38;5;66;03m# yield embedding tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\engine\\predictor.py:182\u001b[0m, in \u001b[0;36mBasePredictor.inference\u001b[1;34m(self, im, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Run inference on a given image using the specified model and arguments.\"\"\"\u001b[39;00m\n\u001b[0;32m    177\u001b[0m visualize \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    178\u001b[0m     increment_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_dir \u001b[38;5;241m/\u001b[39m Path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mstem, mkdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mvisualize \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_type\u001b[38;5;241m.\u001b[39mtensor)\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    181\u001b[0m )\n\u001b[1;32m--> 182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\autobackend.py:644\u001b[0m, in \u001b[0;36mAutoBackend.forward\u001b[1;34m(self, im, augment, visualize, embed, **kwargs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# PyTorch\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpt \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnn_module:\n\u001b[1;32m--> 644\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maugment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    646\u001b[0m \u001b[38;5;66;03m# TorchScript\u001b[39;00m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:139\u001b[0m, in \u001b[0;36mBaseModel.forward\u001b[1;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):  \u001b[38;5;66;03m# for cases of training and validating while training.\u001b[39;00m\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(x, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:157\u001b[0m, in \u001b[0;36mBaseModel.predict\u001b[1;34m(self, x, profile, visualize, augment, embed)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m augment:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict_augment(x)\n\u001b[1;32m--> 157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisualize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\tasks.py:180\u001b[0m, in \u001b[0;36mBaseModel._predict_once\u001b[1;34m(self, x, profile, visualize, embed)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m profile:\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_profile_one_layer(m, x, dt)\n\u001b[1;32m--> 180\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# run\u001b[39;00m\n\u001b[0;32m    181\u001b[0m y\u001b[38;5;241m.\u001b[39mappend(x \u001b[38;5;28;01mif\u001b[39;00m m\u001b[38;5;241m.\u001b[39mi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# save output\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m visualize:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:318\u001b[0m, in \u001b[0;36mC2f.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 318\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:318\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through C2f layer.\"\"\"\u001b[39;00m\n\u001b[0;32m    317\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x)\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 318\u001b[0m y\u001b[38;5;241m.\u001b[39mextend(\u001b[43mm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mm)\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(torch\u001b[38;5;241m.\u001b[39mcat(y, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\block.py:495\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply bottleneck with optional shortcut connection.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv1(x))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\ultralytics\\nn\\modules\\conv.py:92\u001b[0m, in \u001b[0;36mConv.forward_fuse\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_fuse\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     83\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;124;03m    Apply convolution and activation without batch normalization.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;124;03m        (torch.Tensor): Output tensor.\u001b[39;00m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the model\n",
    "yolo = YOLO('yolov8s.pt')\n",
    "\n",
    "# Load the video capture\n",
    "videoCap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (1, -1, 2)]\n",
    "    color = [base_colors[color_index][i] + increments[color_index][i] * \n",
    "    (cls_num // len(base_colors)) % 256 for i in range(3)]\n",
    "    return tuple(color)\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = videoCap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    results = yolo.track(frame, stream=True)\n",
    "\n",
    "\n",
    "    for result in results:\n",
    "        # get the classes names\n",
    "        classes_names = result.names\n",
    "\n",
    "        # iterate over each box\n",
    "        for box in result.boxes:\n",
    "            # check if confidence is greater than 40 percent\n",
    "            if box.conf[0] > 0.4:\n",
    "                # get coordinates\n",
    "                [x1, y1, x2, y2] = box.xyxy[0]\n",
    "                # convert to int\n",
    "                x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "                # get the class\n",
    "                cls = int(box.cls[0])\n",
    "\n",
    "                # get the class name\n",
    "                class_name = classes_names[cls]\n",
    "\n",
    "                # get the respective colour\n",
    "                colour = getColours(cls)\n",
    "\n",
    "                # draw the rectangle\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
    "\n",
    "                # put the class name and confidence on the image\n",
    "                cv2.putText(frame, f'{classes_names[int(box.cls[0])]} {box.conf[0]:.2f}', (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, colour, 2)\n",
    "                \n",
    "    # show the image\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# release the video capture and destroy all windows\n",
    "videoCap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a208a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.178-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.7.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (4.67.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (5.9.8)\n",
      "Collecting py-cpuinfo (from ultralytics)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from ultralytics) (2.2.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.15-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.23.0->ultralytics) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (2025.2.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from torch>=1.8.0->ultralytics) (76.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\srinidhi\\appdata\\roaming\\python\\python312\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
      "Downloading ultralytics-8.3.178-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.3/1.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 819.2 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 819.2 kB/s eta 0:00:01\n",
      "   ------------------------------ --------- 0.8/1.0 MB 819.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 595.1 kB/s eta 0:00:00\n",
      "Downloading ultralytics_thop-2.0.15-py3-none-any.whl (28 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: py-cpuinfo, ultralytics-thop, ultralytics\n",
      "\n",
      "   ---------------------------------------- 0/3 [py-cpuinfo]\n",
      "   ---------------------------------------- 0/3 [py-cpuinfo]\n",
      "   ------------- -------------------------- 1/3 [ultralytics-thop]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   -------------------------- ------------- 2/3 [ultralytics]\n",
      "   ---------------------------------------- 3/3 [ultralytics]\n",
      "\n",
      "Successfully installed py-cpuinfo-9.0.0 ultralytics-8.3.178 ultralytics-thop-2.0.15\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "136a6fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 12 persons, 1 umbrella, 399.0ms\n",
      "Speed: 5.8ms preprocess, 399.0ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "imshow() missing 1 required positional argument: 'mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mputText(frame, label, (x1, y1 \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m),\n\u001b[0;32m     38\u001b[0m                         cv2\u001b[38;5;241m.\u001b[39mFONT_HERSHEY_SIMPLEX, \u001b[38;5;241m0.8\u001b[39m, colour, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Show image with detections\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     43\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[1;31mTypeError\u001b[0m: imshow() missing 1 required positional argument: 'mat'"
     ]
    }
   ],
   "source": [
    "# for image \n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "# Load the model\n",
    "yolo = YOLO('yolov8s.pt')\n",
    "\n",
    "# Load image from file\n",
    "image_path = r\"C:\\Users\\SRINIDHI\\OneDrive\\Desktop\\Deep Learning\\Assignment 7\\crowded-place.jpeg\"  # Change this to your image file path\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "# Function to get class colors\n",
    "def getColours(cls_num):\n",
    "    base_colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]\n",
    "    color_index = cls_num % len(base_colors)\n",
    "    increments = [(1, -2, 1), (-2, 1, -1), (2, -1, 1)]\n",
    "    color = [\n",
    "        max(0, min(255, base_colors[color_index][i] +\n",
    "                   increments[color_index][i] * (cls_num // len(base_colors))))\n",
    "        for i in range(3)\n",
    "    ]\n",
    "    return tuple(color)\n",
    "\n",
    "# Run object detection\n",
    "results = yolo(frame)\n",
    "\n",
    "for result in results:\n",
    "    classes_names = result.names\n",
    "    for box in result.boxes:\n",
    "        if box.conf[0] > 0.4:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cls = int(box.cls[0])\n",
    "            colour = getColours(cls)\n",
    "            label = f\"{classes_names[cls]} {box.conf[0]:.2f}\"\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), colour, 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, colour, 2)\n",
    "\n",
    "# Show image with detections\n",
    "cv2.imshow(frame)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d331c585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
